# ğŸ¥ A Medical Document Conversational Framework Using MedGemma  
### Reliable Cancer Screening Assistance using MEDGemma + GenAI

A GenAI-powered medical document chatbot that helps users understand cancer screening related medical reports using **MedGemma (Googleâ€™s medical LLM)** and **Retrieval-Augmented Generation (RAG)**.

> âš ï¸ Academic project for educational purposes only. Not a medical diagnosis system.

![Python](https://img.shields.io/badge/Python-3.9+-blue?logo=python)  
![GenAI](https://img.shields.io/badge/GenAI-MedGemma-purple)  
![RAG](https://img.shields.io/badge/Architecture-RAG-orange)  

---

## 1ï¸âƒ£ Introduction  
Medical reports are often difficult for non-experts to understand. This project builds a **medical document conversational AI system** that allows users to upload medical reports (PDFs, scanned images, DOCX) and ask questions related to **cancer screening**.  

By combining **document retrieval** with **MedGemma**, the system generates **context-aware and reliable answers** grounded in the uploaded medical content.

---

## 2ï¸âƒ£ Overview  
The system follows a **Retrieval-Augmented Generation (RAG)** pipeline:

- User uploads a medical document  
- Text is extracted using PDF parsers and OCR  
- Document is split into chunks  
- Relevant chunks are retrieved using embeddings + FAISS  
- MedGemma LLM generates an answer using retrieved context  
- The response is delivered in a patient-friendly format  

This approach reduces hallucinations and improves trustworthiness.

---

## 3ï¸âƒ£ Demos  

### ğŸ§± Architecture  
![Architecture](assets/architecture.jpg)

**Pipeline:**  
User â†’ Query Understanding â†’ Document Retrieval â†’ RAG Integration (MedGemma) â†’ Answer Synthesis â†’ Result Delivery

---

## ğŸ“‚ Project Structure

```text
medical-document-conversational-framework/
â”œâ”€â”€ medgemma.py        # Loads MedGemma model
â”œâ”€â”€ file_loader.py    # File loaders (PDF, DOCX, Images)
â”œâ”€â”€ ocr.py            # OCR utilities (PyTesseract)
â”œâ”€â”€ embeddings.py     # Embedding model loader
â”œâ”€â”€ retriever.py      # Text chunking logic
â”œâ”€â”€ vectorstore.py    # FAISS vector store
â”œâ”€â”€ store.py          # LangChain FAISS store
â”œâ”€â”€ app.py            # Main application (CLI / Streamlit-ready)
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ architecture.jpg
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

---

## 5ï¸âƒ£ Deployed / Run Locally  

- âœ… Run Locally / Google Colab  
- âŒ Not deployed publicly (medical model + GPU constraints)  
- ğŸ”® Can be deployed on Streamlit Cloud / Hugging Face Spaces in future  

---

## 6ï¸âƒ£ Deployment Guide (Google Colab)

### ğŸ”§ Install Dependencies  
```bash
pip install -U torch transformers accelerate sentence-transformers langchain faiss-cpu pytesseract pillow python-dotenv streamlit pdfplumber pymupdf python-docx pandas
ğŸ” Set HuggingFace Token (Secure)
from google.colab import userdata
userdata.set("HUGGINGFACEHUB_API_TOKEN", "YOUR_TOKEN")

âŒ Do NOT hardcode tokens in code or push them to GitHub.

â–¶ï¸ Run
python app.py
7ï¸âƒ£ Tech Stack

Language: Python

LLM: MedGemma (google/medgemma-1.5-4b-it)

Frameworks: Hugging Face Transformers, LangChain

Vector DB: FAISS

Embeddings: Sentence Transformers

OCR: PyTesseract

PDF Parsing: PDFPlumber, PyMuPDF

Frontend (Optional): Streamlit

Platform: Google Colab / Local

ğŸ“Œ Conclusion

This project demonstrates how GenAI + RAG can be applied to medical document understanding for reliable cancer screening assistance. The architecture ensures answers are grounded in source documents, improving explainability and trust.

ğŸ‘¨â€ğŸ“ Author

Final Year B.Tech (AI & DS)
India
